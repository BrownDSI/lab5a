{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be7945d65d1c2b6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Lab5: MapReduce\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "[MapReduce](https://en.wikipedia.org/wiki/MapReduce) is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster.\n",
    "\n",
    "A MapReduce program is composed of a Map() procedure (method) that performs filtering and sorting (such as sorting students by first name into queues, one queue for each name) and a Reduce() method that performs a summary operation (such as counting the number of students in each queue, yielding name frequencies). \n",
    "\n",
    "High performance implementations of \"MapReduce Systems\" (also called \"infrastructures\" or \"frameworks\") orchestrate the processing by marshaling distributed servers, running the various tasks in parallel, managing all communications and data transfers between the various parts of the system, and providing for redundancy and fault tolerance. The model is a specialization of the split-apply-combine strategy.\n",
    "\n",
    "In this lab, you will use MapReduce to 1) create an inverted index and 2) do some matrix algebra.  The package `mapreduce.py` included with this lab simulates [Apache Spark](https://spark.apache.org/), a high performance MapReduce framework commonly used in many big data applications.\n",
    "\n",
    "#### Example\n",
    "Below is a simple word counting example.  The `mapper1` function returns a list of (key, value) pairs consisting of (word,1) tuples, where word is each word in a document, and a `reducer` function adds all the values for each set of identical keys (in this case words) in order to calculate counts for each word.  \n",
    "\n",
    "The line starting with to `sc.parallelize` invokes the Spark MapReduce framework.  See the [Spark documentation](https://spark.apache.org/docs/latest/api/python/pyspark.html) for more details on the methods and parameters being used to control the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ffcf3800592dcdc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mapreduce import mapreduce\n",
    "from pprint import pprint\n",
    "import string\n",
    "\n",
    "def mapper1(s):\n",
    "    '''\n",
    "    Returns a list of tuples of the form (word,1) \n",
    "    for every word in string s \n",
    "    '''\n",
    "    words = s.split()\n",
    "    result = [(word, 1) for word in words]\n",
    "    print('mapper1: %s -> %s'%(s,result))\n",
    "    return result\n",
    "    \n",
    "def reducer(a, b):\n",
    "    'Returns the sum of word count results a and b'\n",
    "    return a + b\n",
    "\n",
    "def word_count(text):\n",
    "    '''\n",
    "    Returns a list of (word,count) tuples\n",
    "    '''\n",
    "    if isinstance(text,str):\n",
    "        text = [text]\n",
    "    # Remove punctuation    \n",
    "    translator = str.maketrans('', '', string.punctuation+'\\n')\n",
    "    text = [line.translate(translator).lower() for line in text] \n",
    "    \n",
    "    # Count words using MapReduce\n",
    "    ## print('MapReduce Input:')\n",
    "    pprint(text)\n",
    "    sc = mapreduce()\n",
    "    word_count_result = sc.parallelize(text, 4)\\\n",
    "        .flatMap(mapper1)\\\n",
    "        .reduceByKey(reducer)\\\n",
    "        .sortByKey(True)\\\n",
    "        .collect()\n",
    "    sc.stop()\n",
    "    ## print('MapReduce Output:')\n",
    "    ## pprint(word_count_result)\n",
    "    return word_count_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count('A rose is a rose is a rose.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('data/hadoop.txt', 'r')\n",
    "r = word_count(text)    \n",
    "r[0:10] # Print out the first 10 counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 0\n",
    "Re-run the above example after you uncomment `## print` statements.  While looking at the annotated output try and get a clear understanding what `mapper1` does, and how it's output is consolidated via `.reduceByKey(reducer)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c3a6f546ceda9840",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### TASK 1\n",
    "Given a set of documents, an inverted index is a dictionary where each word is associated with a list of the document names in which that word appears. Fill in the `mapper1`, `reducer`, and `mapper2` functions to create an inverted index of `hadoop.txt`. Refer to the docstrings of these function to see what the expected input and output formats are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec7341555f738222",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def mapper1(document):\n",
    "    \"\"\"\n",
    "    Given a document consisting of a (title, text) pair returns \n",
    "    a list of (word,[title]) pairs for every word in the text.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "def reducer(a, b):\n",
    "    \"\"\"\n",
    "    Returns the concatenation of a document title b, stored in a list, \n",
    "    to a list of document titles a.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "def mapper2(record):\n",
    "    \"\"\"\n",
    "    Assumes record is in (word, [title1, title2, ...]) format.\n",
    "    Returns a version of record (word, [title1*, title2*, ...]) where\n",
    "    [title1*, tite2*, ...] is a sorted list of unique titles.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "def inverted_index(texts):\n",
    "    '''\n",
    "    Return an inverted word index on list of texts given \n",
    "    in [title, text] format.\n",
    "    '''\n",
    "    # Preprocess texts to eliminate punctuation, numbers \n",
    "    # and make them lower cases\n",
    "    translator = str.maketrans('', '', string.punctuation+'0123456789')\n",
    "    texts = [[title,text.translate(translator).lower()] for [title,text] in texts]\n",
    "    \n",
    "    # Compute inverted index using map reduce\n",
    "    sc = mapreduce()\n",
    "    inv_index = sc.parallelize(texts, 128) \\\n",
    "        .flatMap(mapper1) \\\n",
    "        .reduceByKey(reducer) \\\n",
    "        .sortByKey(True) \\\n",
    "        .map(mapper2) \\\n",
    "        .collect()\n",
    "    sc.stop()\n",
    "    return inv_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some output:\n",
    "~~~~\n",
    ">>> inverted_index([['Mavis-Typing 101','The quick brown fox jumped over the lazy dog!'], \n",
    "                    ['Milne-Winne the Pooh', 'Pooh and the brown fox best of friends.']])\n",
    "                \n",
    "[('and', ['Milne-Winne the Pooh']),\n",
    " ('best', ['Milne-Winne the Pooh']),\n",
    " ('brown', ['Mavis-Typing 101', 'Milne-Winne the Pooh']),\n",
    " ('dog', ['Mavis-Typing 101']),\n",
    " ('fox', ['Mavis-Typing 101', 'Milne-Winne the Pooh']),\n",
    " ('friends', ['Milne-Winne the Pooh']),\n",
    " ('jumped', ['Mavis-Typing 101']),\n",
    " ('lazy', ['Mavis-Typing 101']),\n",
    " ('of', ['Milne-Winne the Pooh']),\n",
    " ('over', ['Mavis-Typing 101']),\n",
    " ('pooh', ['Milne-Winne the Pooh']),\n",
    " ('quick', ['Mavis-Typing 101']),\n",
    " ('the', ['Mavis-Typing 101', 'Milne-Winne the Pooh'])]\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep updating your code until you can reproduce the above result \n",
    "# by running the command below\n",
    "inverted_index([['Mavis-Typing 101','The quick brown fox jumped over the lazy dog!'], \n",
    "              ['Milne-Winne the Pooh', 'Pooh and the brown fox best of friends.']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have your code working, try this more complex \n",
    "# example on a JSON file full of books\n",
    "with open('data/books.json', 'r') as infile:\n",
    "        texts = [json.loads(line) for line in infile]\n",
    "inv_ind = inverted_index(texts)\n",
    "inv_ind[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "1. What happens if you eliminate the use of `mapper2`? (i.e., remove the `.map(mapper2)` call in `sc.parallelize`) \n",
    "2. Why didnt't we need to do a reduce step after `mapper2` was applied? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fill in your answer below:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "Can you see an easy way to add a count of the total number of times \n",
    "a word appears in all texts?  Implement your solution below.  Here's some example output:\n",
    "~~~~\n",
    ">>> inv_ind = inverted_index([['Mavis-Typing 101','The quick brown fox jumped over the lazy dog!'], \n",
    "              ['Milne-Winne the Pooh', 'Pooh and the brown fox best of friends.']])\n",
    "\n",
    "[('and', 1, ['Milne-Winne the Pooh']),\n",
    " ('best', 1, ['Milne-Winne the Pooh']),\n",
    " ('brown', 2, ['Mavis-Typing 101', 'Milne-Winne the Pooh']),\n",
    " ('dog', 1, ['Mavis-Typing 101']),\n",
    " ('fox', 2, ['Mavis-Typing 101', 'Milne-Winne the Pooh']),\n",
    " ('friends', 1, ['Milne-Winne the Pooh']),\n",
    " ('jumped', 1, ['Mavis-Typing 101']),\n",
    " ('lazy', 1, ['Mavis-Typing 101']),\n",
    " ('of', 1, ['Milne-Winne the Pooh']),\n",
    " ('over', 1, ['Mavis-Typing 101']),\n",
    " ('pooh', 1, ['Milne-Winne the Pooh']),\n",
    " ('quick', 1, ['Mavis-Typing 101']),\n",
    " ('the', 3, ['Mavis-Typing 101', 'Milne-Winne the Pooh'])]\n",
    " ~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Test your solution\n",
    "inv_ind = inverted_index([['Mavis-Typing 101','The quick brown fox jumped over the lazy dog!'], \n",
    "              ['Milne-Winne the Pooh', 'Pooh and the brown fox best of friends.']])\n",
    "\n",
    "pprint(inv_ind)\n",
    "\n",
    "with open('data/books.json', 'r') as infile:\n",
    "        texts = [json.loads(line) for line in infile]\n",
    "inv_ind = inverted_index(texts)\n",
    "inv_ind[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Algebra\n",
    "There are a variety of ways represent matrices inside of a computer.  By organizing the way elements are stored (e.g., column-wise versus row-wise) some calculations will be faster, other slower. Similarly, the way elements are stored is also important.  Some matrices have a regular structure (e.g. diagonal matrices, e.g. symmetric matrices) which means storing every element is not required.  Others may contain mostly zero elements, in which case just storing the non-zero elements may make sense. Such matrices are known as sparse matrices, and there are there are 7 different  [SciPy sparse matrix types](https://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse) available for storing matrices of this type. \n",
    "\n",
    "In this part of the lab we are going to use a simple sparse matrix representation `SpMatrix` that is similar to  SciPy's [scipy.sparse.coo](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html#scipy.sparse.coo_matrix) class.  The idea is to store the non-zero elements of a matrix in (i,j,v) format, where (i,j) is an elements position and v is it's value.  \n",
    "\n",
    "Using this approach allows one to write MapReduce algorithms that can work on truly massive matrices.  Below is the class definition for `SpMatrix` and an examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Sparse Matrix class\n",
    "class SpMatrix:\n",
    "    def __init__(self, m=1, n=1, ijv=[]):\n",
    "        '''\n",
    "        m: number rows\n",
    "        n: number columns\n",
    "        ijv: list of ((i, j), value) tuples\n",
    "        '''\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.ijv = ijv\n",
    "    def np(self):\n",
    "        '''Returns self as a NumPy Array'''\n",
    "        r = np.zeros((self.m,self.n))\n",
    "        for (ij,v) in self.ijv:\n",
    "            r[ij[0],ij[1]]=v\n",
    "        return r\n",
    "    def __str__(self):\n",
    "        return self.np().__str__()\n",
    "\n",
    "# Create the matrix\n",
    "# A = [10   0   30;\n",
    "#      40  50  -30]\n",
    "A =  SpMatrix(2,3, [((0,0),10), ((0,2),30),((1,0),40),((1,1),50),((1,2),-30)])\n",
    "print(\"A's internal storage = \\n\", A.ijv)\n",
    "print(\"Matrix A represents = \\n\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "Write a function SpEye(n) that returns an n by n identity SpMatrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "print(SpEye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 5 \n",
    "The `col_sum` function below takes an SpMatrix as input, and returns the sum of each of it's columns as another SpMatrix.  Test the code out, and then uncomment the print statements to get a better feel on how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper1(ijv):\n",
    "    '''\n",
    "    Returns [(0,j),val)] given an ijv tuple ((i, j), val).\n",
    "    '''\n",
    "    result = [((0,ijv[0][1]), ijv[1])]\n",
    "    ## print('mapper1: %s -> %s'%(ijv, result))\n",
    "    return result\n",
    "\n",
    "def reducer(a, b):\n",
    "    return a + b\n",
    " \n",
    "def col_sum(A):\n",
    "    sc = mapreduce()\n",
    "    ## print('MapReduce Input:')\n",
    "    ## pprint(A.ijv)\n",
    "    col_sum = sc.parallelize(A.ijv, 4) \\\n",
    "        .flatMap(mapper1) \\\n",
    "        .reduceByKey(reducer) \\\n",
    "        .sortByKey(True)\\\n",
    "        .collect()\n",
    "    sc.stop()\n",
    "    ## print('MapReduce Output:')\n",
    "    ## pprint(col_sum)\n",
    "    return SpMatrix(1, A.n, col_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = SpMatrix(2, 3, [((0, 0), 20), ((0, 1), 40), ((1, 1), 50), ((1, 2), 30)])\n",
    "print('A = \\n%s'%(A))\n",
    "print()\n",
    "cs = col_sum(A)\n",
    "print()\n",
    "print('col_sum(A) = \\n', cs)\n",
    "assert np.all(cs.np()==np.sum(A.np(),0)) # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK 6\n",
    "Complete the code block below to compute the ** element-wise sum ** of two SpMatrices. Include a simple test using an assert to check that your solution is working.\n",
    "\n",
    "Below is some example output.\n",
    "\n",
    "Notice that the input created for the MapReduce (see `MapReduce Input:` below) is a list containing both matrices' elements.  This is the general setup for handling matrix algebra using MapReduce.     \n",
    "~~~~\n",
    "A = SpMatrix(2, 3, [((0, 0), 1), ((1, 1), 1), ((1,2),1)])\n",
    "B = SpMatrix(2, 3, [((0, 0), 2), ((0, 1), 1), ((1, 0), 3), ((1,2), -1)])\n",
    "print('A = \\n%s'%(A))\n",
    "print('B = \\n%s'%(B))\n",
    "print()\n",
    "result = sp_sum(A, B)\n",
    "print()\n",
    "print('sp_sum(A,B) = \\n%s'%(result))\n",
    "---\n",
    "A = \n",
    "[[ 1.  0.  0.]\n",
    " [ 0.  1.  1.]]\n",
    "B = \n",
    "[[ 2.  1.  0.]\n",
    " [ 3.  0. -1.]]\n",
    "\n",
    "MapReduce Input: \n",
    "[(('a', 0, 0), 1),\n",
    " (('a', 1, 1), 1),\n",
    " (('a', 1, 2), 1),\n",
    " (('b', 0, 0), 2),\n",
    " (('b', 0, 1), 1),\n",
    " (('b', 1, 0), 3),\n",
    " (('b', 1, 2), -1)]\n",
    "mapper1: (('a', 0, 0), 1) -> [((0, 0), 1)]\n",
    "mapper1: (('a', 1, 1), 1) -> [((1, 1), 1)]\n",
    "mapper1: (('a', 1, 2), 1) -> [((1, 2), 1)]\n",
    "mapper1: (('b', 0, 0), 2) -> [((0, 0), 2)]\n",
    "mapper1: (('b', 0, 1), 1) -> [((0, 1), 1)]\n",
    "mapper1: (('b', 1, 0), 3) -> [((1, 0), 3)]\n",
    "mapper1: (('b', 1, 2), -1) -> [((1, 2), -1)]\n",
    "MapReduce Output:\n",
    "[((0, 0), 3), ((0, 1), 1), ((1, 0), 3), ((1, 1), 1), ((1, 2), 0)]\n",
    "\n",
    "sp_sum(A,B) = \n",
    "[[ 3.  1.  0.]\n",
    " [ 3.  1.  0.]]\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper1(sijv):\n",
    "    '''\n",
    "    Given a record tuple ((s,i,j),value))\n",
    "    Returns [((i,j), value)] \n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "def reducer(a, b):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "def sp_sum(A,B):\n",
    "    assert A.m==B.m and A.n==B.n\n",
    "    sijv = [(('a',ijv[0][0], ijv[0][1]), ijv[1]) for ijv in A.ijv]\n",
    "    sijv += [(('b',ijv[0][0], ijv[0][1]), ijv[1]) for ijv in B.ijv]\n",
    "    sc = mapreduce()\n",
    "    print('MapReduce Input: ')\n",
    "    pprint(sijv)\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# Software Test(s)\n",
    "###\n",
    "print(sp_sum(SpEye(2),SpEye(2)))\n",
    "assert(np.all(sp_sum(SpEye(2),SpEye(2)).np()==SpMatrix(2,2,[((0,0),2),((1,1),2)]).np()))\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = SpMatrix(2, 3, [((0, 0), 1), ((1, 1), 1), ((1,2),1)])\n",
    "B = SpMatrix(2, 3, [((0, 0), 2), ((0, 1), 1), ((1, 0), 3), ((1,2), -1)])\n",
    "print('A = \\n%s'%(A))\n",
    "print('B = \\n%s'%(B))\n",
    "print()\n",
    "result = sp_sum(A, B)\n",
    "print()\n",
    "print('sp_sum(A,B) = \\n%s'%(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
